<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Bayesian inference in a probabilistic program</title>
  <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.6.0/pure-min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/code.css">
  <!-- Katex Script -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.css">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@100;300;700;900&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=PT+Serif:ital@1&display=swap" rel="stylesheet">

  <link rel="canonical" href="http://localhost:4000/bdappl/chapters/app-02-inference.html">
  <script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.js"></script>
  <script src="/assets/js/parse-bibtex.js"></script>
  <script src="/assets/js/main.js"></script>

  <script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.js"></script>
  <link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>


  <script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.js"></script>
  <link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.css">
  <!-- <link rel="stylesheet" href="http://127.0.0.1:8888/home/wp/viz/demo/webppl-viz.css"> -->
  <!-- <script src="http://127.0.0.1:8888/home/wp/viz/demo/webppl-viz.js"></script> -->

  <script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-v0.9.13.js"></script>
</head>

  <body>

    <header class="site-header">
  <a class="site-title">Bayesian <span>Machine Learning</span></a>
</header>


    <div class="page-content-wrapper">
      <div class="page-content">
        <h1 class="chapter-title">Bayesian inference in a probabilistic program</h1>

<h4 id="learning-about-parameters-from-data">Learning about parameters from data</h4>

<p>Having specified our <em>a priori</em> state of knowledge about the parameter of interest, and the generative process of the data given a particular value of the parameter, we are ready to make inferences about the likely value of the parameter given our observed data.
We do this via <em>Bayesian inference</em>, the mathematically correct way of reasoning about the underlying probability that generated our data.</p>

<p>So we run the experiment, and 15 out of 20 kids performed the helping behavior.
Thus, <code class="language-plaintext highlighter-rouge">numberOfHelpfulResponses == 15</code>.
How can we tell our model about this?</p>

<pre><code class="language-norun">var sampleAndObserve = function(){
  var propensityToHelp = sample(PriorDistribution)
  var numberOfHelpfulResponses = binomial({
    p: propensityToHelp,
    n: numberOfKidsTested
  })
  var matchesOurData = (numberOfHelpfulResponses == 15)
  return ...
}
</code></pre>

<p>What should we return?
We could return <code class="language-plaintext highlighter-rouge">matchesOurData</code>.
If we repeat this function many times, we will estimate how many <code class="language-plaintext highlighter-rouge">propensityToHelp</code>s under our prior (i.e., between 0 - 1) give rise to our observed data.
This is called the <strong>likelihood of the data</strong>, but is not immediately interpretable in isolation (though we will see it later in this course).</p>

<p>What if we returned <code class="language-plaintext highlighter-rouge">propensityToHelp</code>?
Well, that will just give us the same prior that we saw above, because there is no relationship in the program between <code class="language-plaintext highlighter-rouge">matchesOurData</code> and <code class="language-plaintext highlighter-rouge">propensityToHelp</code>.</p>

<p>What if we returned <code class="language-plaintext highlighter-rouge">propensityToHelp</code>, but only if <code class="language-plaintext highlighter-rouge">matchesOurData</code> is <code class="language-plaintext highlighter-rouge">true</code>?
In principle, any value <code class="language-plaintext highlighter-rouge">propensityToHelp</code> <em>could</em> give rise to our data, but intuitively some values are more likely to than others (e.g., a <code class="language-plaintext highlighter-rouge">propensityToHelp</code> = 0.2, would produce 15 out of 20 successes with probability proportional to \(0.2^{15} + 0.8^5\), which is not as likely as a <code class="language-plaintext highlighter-rouge">propensityToHelp</code> = 0.8 would have in producing 15 out of 20 success).</p>

<p>It turns out, if you repeat that procedure many times, then the values that survive this “rejection” procedure, survive it in proportion to the actual <em>a posteriori</em> probability of those values given the observed data. 
It is a mathematical manifestation of the quotation from Arthur Conan Doyle’s <em>Sherlock Holmes</em>: “Once you eliminate the impossible, whatever remains, no matter how improbable, must be the truth.”
Thus, we eliminate the impossible (and, implicitly, we penalize the improbable), and what we are left with is a distribution that reflects our state of knowledge after having observed the data we collected.</p>

<p>We’ll use the <code class="language-plaintext highlighter-rouge">editor.put()</code> function to save our results so we can look at the them in different code boxes.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var PriorDistribution = Uniform({a:0, b:1});
var numberOfKidsTested = 20;

var sampleAndObserve = function(){
  var propensityToHelp = sample(PriorDistribution)
  var numberOfHelpfulResponses = binomial({
    p: propensityToHelp,
    n: numberOfKidsTested
  })
  var matchesOurData = (numberOfHelpfulResponses == 15)
  return matchesOurData ? propensityToHelp : "reject"
}

var exampleOutput = repeat(10, sampleAndObserve)

display("___example output from function___")
display(exampleOutput)

// remove all the rejects
var posteriorSamples = filter(
  function(s){return s != "reject" },
  repeat(100000, sampleAndObserve)
)

// save results in browser cache to access them later
editor.put("posteriorSamples", posteriorSamples)

viz(posteriorSamples)
</code></pre></div></div>

<p>Visualized from the code box above is the <em>posterior distribution</em> over the parameter <code class="language-plaintext highlighter-rouge">propensityToHelp</code>.
It represents our state of knowledge about the parameter after having observed the data (15 out of 20 success).</p>

<h4 id="the-inference-algorithm">The inference algorithm</h4>

<p>The procedure we implemented in the above code box is called <a href="https://en.wikipedia.org/wiki/Rejection_sampling">Rejection sampling</a>, and it is the simplest algorithm for <a href="https://en.wikipedia.org/wiki/Bayesian_inference">Bayesian inference</a>.</p>

<p>The algorithm can be written as:</p>

<ol>
  <li>Sample a parameter value from the prior (e.g., <code class="language-plaintext highlighter-rouge">p = uniform(0,1)</code>)</li>
  <li>Make a prediction (i.e., generate a possible observed data), given that parameter value (e.g., <code class="language-plaintext highlighter-rouge">binomial( {n:20, p: p} )</code>)
    <ul>
      <li>If the prediction generates the observed data, record parameter value.</li>
      <li>If the prediction doesn’t generate the observed data, throw away that parameter value.</li>
    </ul>
  </li>
  <li>Repeat many times.</li>
</ol>

<p>Just as we saw in the previous chapter, our ability to represent this distribution depends upon the number of samples we take.
Above, we have chosen to take 100000 samples in order to more accurately represent the posterior distribution.
The number of samples doesn’t correspond to anything about our scientific question; it is a feature of the <em>inference algorithm</em>, not of our model.
We will describe inference algorithms in more detail in a later chapter.</p>

<h3 id="abstracting-away-from-the-algorithm-with-infer">Abstracting away from the algorithm with <code class="language-plaintext highlighter-rouge">Infer</code></h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var priorDistribution = Uniform({a:0, b:1});
var numberOfKidsTested = 20;
var model = function() {
  var propensityToHelp = sample(priorDistribution)
  var numberOfHelpfulResponses = binomial({
    p: propensityToHelp,
    n: numberOfKidsTested
  })
  condition(numberOfHelpfulResponses == 15) // condition on data
  return { propensityToHelp }
}

var inferArgument = {
  model: model, 
  method: "rejection", 
  samples: 5000
}

var posteriorDistibution = Infer(inferArgument)

viz(posteriorDistibution)
</code></pre></div></div>

<p>Intuitively, <code class="language-plaintext highlighter-rouge">condition()</code> here operates the same as the conditional return statement in the code box above this one. 
It takes in a boolean value, and throws out the random choices for which that boolean is <code class="language-plaintext highlighter-rouge">false</code>. 
Speaking more generally and technically, <code class="language-plaintext highlighter-rouge">condition()</code> <em>re-weights</em> the probabilities of the <em>program execution</em> (which includes all of the <em>random choices</em> that have been made up to that point in the program) in a binary way: If it’s true, the probability of that program execution gets multiplied by 1 (which has no effect) and if the condition statement is false, the probability of that program execution gets multiplied by 0 (which completely destroys that program execution).</p>

<p><code class="language-plaintext highlighter-rouge">condition()</code> is a special case of <code class="language-plaintext highlighter-rouge">factor()</code>, which directly (and continuously) re-weights the (log) probability of the program execution. 
Whereas <code class="language-plaintext highlighter-rouge">condition()</code> can only take <code class="language-plaintext highlighter-rouge">true</code> or <code class="language-plaintext highlighter-rouge">false</code> as arguments, <code class="language-plaintext highlighter-rouge">factor()</code> takes a number. 
The code above can be rewritten using factor in the following way:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var priorDistribution = Uniform({a:0, b:1});

var model = function() {
  var propensityToHelp = sample(priorDistribution)
  // reweight based on log-prob of observing 15
  factor(Binomial( {n:20, p: propensityToHelp} ).score(15))
  return { propensityToHelp }
}

var posterior = Infer({model: model, method: "rejection", samples: 1000})
viz(posterior)
</code></pre></div></div>

<p>Re-weighting the log-probabilities of a program execution by the (log) probability of a value under a given distribution, as is shown in the code box above, is true Bayesian updating. Because this updating procedure is so commonly used, it gets its own helper function: <code class="language-plaintext highlighter-rouge">observe()</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var model = function() {
  var propensityToHelp = uniform(0,1) // priors
  observe(Binomial( {n:20, p: propensityToHelp} ), 15) // observe 15 from the Binomial dist
  return { propensityToHelp }
}

var posterior = Infer({model: model, method: "rejection", samples: 1000})
viz(posterior)
</code></pre></div></div>

<h4 id="observe-condition-and-factor-distilled">Observe, condition, and factor: distilled</h4>

<p>The helper functions <code class="language-plaintext highlighter-rouge">condition()</code>, <code class="language-plaintext highlighter-rouge">observe()</code>, and <code class="language-plaintext highlighter-rouge">factor()</code> all have the same underlying purpose: Changing the probability of different program executions. For Bayesian data analysis, we want to do this in a way that computes the posterior distribution.</p>

<p>Imagine running a model function a single time. 
In some lines of the model code, the program makes <em>random choices</em> (e.g., flipping a coin and it landing on heads, or tails).
The collection of all the random choices in an execution of every line of a program is referred to as the program execution.</p>

<p>Different random choices may have different (prior) probabilities (or perhaps, you have uninformed priors on all of the parameters, and then they each have equal probability).
What <code class="language-plaintext highlighter-rouge">observe</code>, <code class="language-plaintext highlighter-rouge">condition</code>, and <code class="language-plaintext highlighter-rouge">factor</code> do is change the probabilities of these different random choices. 
For Bayesian data analysis, we use these terms to change the probabilities of these random choices to align with the true posterior probabilities. 
For BDA, this is usually achived using <code class="language-plaintext highlighter-rouge">observe</code>.</p>

<p><code class="language-plaintext highlighter-rouge">factor</code> is the most primitive of the three, and <code class="language-plaintext highlighter-rouge">observe</code> and <code class="language-plaintext highlighter-rouge">condition</code> are both special cases of <code class="language-plaintext highlighter-rouge">factor</code>. 
<code class="language-plaintext highlighter-rouge">factor</code> directly re-weights the log-probability of program executions, and it takes in a single numerical argument (how much to re-weight the log-probabilities). 
<code class="language-plaintext highlighter-rouge">observe</code> is a special case where you want to re-weight the probabilities by the probability of the observed data under some distribution. <code class="language-plaintext highlighter-rouge">observe</code> thus takes in two arguments: a distribution and an observed data point.</p>

<p><code class="language-plaintext highlighter-rouge">condition</code> is a special case where you want to completely reject or rule out certain program executions.
<code class="language-plaintext highlighter-rouge">condition</code> takes in a single <em>boolean</em> argum</p>

<p>Here is a summary of the three statements.</p>

<pre><code class="language-norun">factor(val)
observe(Dist, val) === factor(Dist.score(val)) 
                   === condition(sample(Dist) == val)
condition(bool) === factor(bool ? 0 : -Infinity)
</code></pre>


<hr>

<a href="/">Table of Contents</a>

      </div>
    </div>

    <footer class="site-footer">
  <a href="" id="github-edit-link">Edit on Github</a>
</footer>

<script type="text/javascript">
  $("#github-edit-link").attr("href", github_page_url("/chapters/app-02-inference.html"))
</script>


  </body>

</html>
