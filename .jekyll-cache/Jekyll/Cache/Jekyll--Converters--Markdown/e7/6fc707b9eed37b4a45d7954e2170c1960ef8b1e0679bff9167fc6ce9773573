I"th<h1 id="bayesian-probabilities-an-introduction">Bayesian Probabilities: An Introduction</h1>

<p>Bayesian probability is a field within the larger field of <a href="https://en.wikipedia.org/wiki/Bayesian_statistics">Bayesian statistics</a> where 
probability is expressed as a degree of certainty that a particular event will take place. The particular difference in Bayesian probability compared to <a href="https://en.wikipedia.org/wiki/Frequentist_probability">frequentist probability</a> (the more well known approach) is that when calculating probabilities with Bayesian models, we can update our probabilites when a particular event occurs. In more intuitive terms, when we have an event, and we want to calculate its probability, intuitively, we will try to factor in different variables that may affect the likelihood of that event happening; when one of these variables may change, our initial probability may also therefore change - Bayesian models help us do this mathematically. This is best put by some <a href="https://www.stat.auckland.ac.nz/~brewer/stats331.pdf">great lecture notes</a> I found on Bayesian statistics:</p>

<blockquote>
  <p>“When we get new information, we should update our probabilities to take the new information into account. Bayesian methods tell us exactly how to do this.”</p>
</blockquote>

<h2 id="basic-notation-and-terminology">Basic Notation and Terminology</h2>

<h3 id="notation">Notation</h3>

<p>There is some basic terminology and notation worth keeping in mind for this project. Firstly, when refereing to the probability of a certain event occuring, it will be expressed as \(P\ (A)\) where \(A\) is the event.The probability of \(A\) not happening is therefore expressed as \(P\ (\overline{A})\) (this is the complement of the set \(A\), in other words, anything but \(A\))</p>

<blockquote>
\[P\ (A) = 1 - P\ (\overline{A})\]
</blockquote>

<p>If you’re curious about the proof for this expression, here’s an <a href="https://www.thoughtco.com/prove-the-complement-rule-3126554">article</a> on it. It is also worth noting that probabilities are expressed as sets; using the example above, \(A\) is a particular set. 
Therefore, if there are two events (\(A\) and \(B\)), the probability of <em>either event</em> happening can be expressed as:</p>

<blockquote>
\[P\ (A \sqcup B) = P\ (A) + P\ (B)\]
</blockquote>

<p>The probability of both happening would be the <em>intersection</em> of both events; the intersection of both <em>sets</em>. This is expressed as such:</p>

<blockquote>
\[P\ (A \cap B)\]
</blockquote>

<p>The probability of \(A\) happening <em>given that</em> \(B\) has occured, is expressed like so:</p>

<blockquote>
\[P\ (A \mid B)\]
</blockquote>

<p>In any particular scenario all possible outcomes are in the \(\Omega\) (capital <em>omega</em>) set. This is also known as the <em>probability space</em>. If we build on the aforementioned example, 
we may have three possible outcomes: \(A\), \(B\) and \(C\) (all <em>elements</em> of \(\Omega\)).</p>

<blockquote>
\[\therefore \Omega = \{A, B, C\}\]
</blockquote>

<p>Another thing to note, is that \(P\ (\Omega)\) must always be \(=1\) (any event that occurs is part of \(\Omega\) therefore \(P\ (\Omega)\) is inherently certain).</p>

<p>\(\sum\) (capital <em>sigma</em>) set, is also known as the sigma-field. The sigma-field refers to the subsets of a particular probability space used to mathematically define probability (great article on sigma-field <a href="https://www.thoughtco.com/sigma-field-3126572">here</a>). \(\sum\) is a subset of the powerset of \(\Omega\), and remains closed (stable) under comlpements and countable unions</p>

<blockquote>
\[\sum \subseteq \mathcal{P}(\Omega)\]
</blockquote>

<blockquote>
\[\ A \in \sum,\ \ \overline{A} \in \sum\]
</blockquote>

<blockquote>
\[\sum \rightarrow [0,\ 1]\]
</blockquote>

<p>Taking the previous example again, this is what \(\sum\) would look like:</p>

<blockquote>
\[\sum = \{\emptyset, \{A\}, \{B\}, \{C\}, \{A, B\}, \{A, C\}, \{B, C\}, \Omega \}\]
</blockquote>

<h3 id="terminology">Terminology</h3>
<p>In Bayesian probability, there are certain terms often used to refer to particular elements in a problem/scenario. Firstly, there are <em>priors</em>, which refer to our probabilities at the start of a problem. There probabilities are the probabilites before any updates or changes have been made (e.g. \(P\ (A)\)).</p>

<p>Once these probabilities are updated with new information, using Bayesain models, they become known as <em>postereior</em> probabilities (e.g. \(P\ (A \mid B)\)).</p>

<h2 id="bayes-theorem">Bayes Theorem</h2>

<p>Bayes Theorem is used to update our prior probabilities with new information, in particular, knowing that a particular event has occured. This is extremely powerful as most probabilities are dependent on other events occuring.</p>

<h3 id="important-note">Important Note</h3>
<p>In typical (basic) textbooks, probability is merely a ratio, and when calculating the probability of two events <em>both</em> happening (\(P\ (A \cap B)\)), both probabilities (\(P\ (A)\) and \(P\ (B)\)) are multiplied together; this implicitly assumes that both events are completely independent and the occurence of \(B\) will not affect \(P\ (A)\) <em>at all</em>. For example, this might be something like flipping a coin and getting heads, and then rolling a dice and getting six. However, this typically only happens in text books, and in real world use cases, the occurence of one event affects the probability that the other will also happen.</p>

<blockquote>
\[P\ (A \cap B) = P\ (A \mid B) \times P\ (B)\]
</blockquote>

<p>This is true because we have accounted for the change in \(P\ (A)\) if \(B\) has also occured</p>

<blockquote>
\[(P\ (A \cap B) = P\ (A) \times P\ (B))\]
</blockquote>

<p>This is only true when the events are completely independent; when:</p>

<blockquote>
\[P\ (A \cap B) = P\ (A)\]
</blockquote>

<h3 id="putting-it-together">Putting It Together</h3>
<p>Moving on from A, B and C, we’ll now use H, for hypothesis, and D, for data (there is reason to do this).</p>

<blockquote>
\[H\ \ \ \ \rightarrow\ \ \ Hypothesis\]
</blockquote>

<blockquote>
\[D\ \ \ \ \rightarrow\ \ \ Data\]
</blockquote>

<blockquote>
\[D,\ H\in\sum\]
</blockquote>

<p>In words, \(P\ (H)\) is the probability that our hypothesis about a given situation is correct, and \(P\ (D)\) is the probability of finding a certain piece of data; making a particular observation for example. With this in mind, as well as what has been mentioned above, we can put together the theorem:</p>

<blockquote>
\[P\ (H \cap D) = P\ (D \cap H)\]
</blockquote>

<blockquote>
\[P\ (D \cap H) = P\ (D \mid H)\times P\ (H)\]
</blockquote>

<blockquote>
\[P\ (H \cap D) = P\ (H \mid D)\times P\ (D)\]
</blockquote>

<blockquote>
\[\therefore P\ (H \mid D)\times P\ (D) = P\ (D \mid H)\times P\ (H)\]
</blockquote>

<blockquote>
\[\therefore P\ (H \mid D) = \\{\\{P\ (D \mid H)\times P\ (H)\\}\over P\ (D)\\}\ \ \ \ \rightarrow\ \ \ Bayes\ Theorem\]
</blockquote>

<p>The first statement demostrates a property known as <em>commutativity</em>, where an operator (in this case \(\cap\)) applied to the second term results in the same outcome as if it was the second term operating on the first. Additionally, this theorem is only applicable when</p>

<blockquote>
\[P\ (D) \neq 0\]
</blockquote>

<p>We can now apply some terminology to the theorem:</p>

<blockquote>
\[P\ (H)\ \ \ \ \rightarrow\ \ \ Prior\]
</blockquote>

<blockquote>
\[P\ (H \mid D)\ \ \ \ \rightarrow\ \ \ Posterior\]
</blockquote>

<blockquote>
\[P\ (D \mid H)\ \ \ \ \rightarrow\ \ \ Likelihood\]
</blockquote>

<blockquote>
\[P\ (D)\ \ \ \ \rightarrow\ \ \ Normalising\ Factor\]
</blockquote>

<p>As one might notice, a little bit of new terminology has been brought up: the <em>likelihood</em> and the <em>normalising factor</em>. The likelihood 
simply refers to the probability that we will make observation \(D\) assuming that we are correct about our hypothesis \(H\).
The normalising factor ensures the final calculated value is within the range 0-1.</p>

<h1 id="the-monty-hall-problem">The Monty Hall Problem</h1>

<h2 id="introduction">Introduction</h2>

<p>Originally from a late 20th century game show, the Monty Hall problem is a staple probability problem, which may initially seem unituitive, but is very interesting to analyse. Consider the following scenario: the show host, named Monty Hall, presents you with 3 doors, two of which are empty (or have ‘goats’ behind them) while the last door has a car. Obviously, your goal is to pick the door with the car to keep it, but you don’t know which door it’s behind.</p>

<p>First, Monty instructs you to make your initial choice; you pick any door of your choice. Monty then proceeds to open another door, where he reveals one of the two goats. You are then presented with the option to either remain with your first choice, the first door you picked, or you may alternatively swtich to the other remaining closed door.</p>

<p>The most interesting part is trying to determine the probability of finding the car in the other door. Intuitively, one might assume the probability is 50/50, however, as can be proven using Bayes Theorem, this is actually not the case. This problem actually stirred up much controversy after its conception between world class mathematicians, but it’s now widely accepted.</p>

<h2 id="manual-approach">Manual Approach</h2>

<p>Before any programming, one should solve it behind to better understand the mechanics behind any solutions using programming.</p>

<h3 id="modeling-the-problem">Modeling the Problem</h3>

<p>First and foremost, one must model the problem such that we can apply the theorem. In this example we’ll modeling as such: \(C\) represents picking the correct door with the car behind it, while \(G_1, G_2\) will represent getting the first/second goat (empty door). It’s worth mentioning that spliting both goats into individual elements is very much deliberate despite perhaps seeming trivial. If we were to keep either goat as just one event, it would involve symmetry in the problem, which will make it significantly more difficult to compute. \(D_1, D_2, D_3\) will represent Monty opening the first/second/third door (respectively).</p>

<blockquote>
\[\{C, G_1, G_2, D_1, D_2, D_3\} \in \sum\]
</blockquote>

<p>Now we can set up a scenario, in order to make it easier for us to digest. Let’s imagine the following:</p>
<ul>
  <li>We pick the first door</li>
  <li>Monty opens the second door</li>
</ul>

<p>We can now define the problem as such:</p>

<blockquote>
\[P\ (C \mid D_2)\ \ \ \ vs\ \ \ \ P\ (\overline{C} \mid D_2)\]
</blockquote>

<p>The first expression addresses the probability that our first choice is right, given that Monty has opened the second door, and the second expression addresses the probability the car is not behind the door that we picked, and is therefore in the other door. If the value of the first expression is greater than the second, we should keep our choice and stay on our door, whereas if the value of the second expression is greater, we should switch doors.</p>

<p>All we need to find is \(P\ (C \mid D_2)\) because we know that \(P\ (C \mid D_2) + P\ ( \overline C \mid D_2) = 1\).</p>

<h3 id="applying-bayes-theorem">Applying Bayes Theorem</h3>

<p>Having modeled the situation appropriately, we can now proceed to solve the problem (manually). Firstly, in terms of Bayes Theorem:</p>

<blockquote>
\[P\ (C \mid D_2) = \\{\\{P\ (D_2 \mid C)\times P\ (C)}\over P\ (D_2)}\]
</blockquote>

<p>We should also establish priors:</p>

<blockquote>
\[C = {1\over3},\ G_1 = {1\over3},\ G_2 = {1\over3}\]
</blockquote>

<p>Now we can compute everything. In this case, the likelihood is the probability that Monty will open the second door (\(D_2\)), <em>given that</em> we have picked the right door on our first try and the car is behind the door we chose (given \(C\)). This means both \(D_2\) and \(D_3\) will have goats, so Monty has an equal chance of picking either door; therefore the likelihood is \(1\over2\).</p>

<p>The prior must be \(1\over3\) because there are three doors and the car could be behind any of them, so \(P\ (C) = {1\over3}\)</p>

<p>Calculating the normalising factor directly in this example is a little bit complicated, but done manually it can be broken down to make it easier. We can break \(P\ (D_2)\) down into the following:</p>

<blockquote>
\[P\ (D_2) = P\ (D_2 \cap C) + P\ (D_2 \cap \overline{C})\]
</blockquote>

<blockquote>
\[= P\ (D_2 \cap C) + P\ (D_2 \cap C_2) + P\ (D_2 \cap C_3)\]
</blockquote>

<p>For the purpose of this example, we’re breaking \(\overline C\) into \(C_2\) and \(C_3\), which represent the car being behind the second and third door, respectively. This is done to make things easier to calculate.</p>

<p>Keeping in mind what was explained above, these can then be further broken down like so:</p>

<blockquote>
\[P\ (D_2 \cap C) = P\ (D_2 \mid C) \times P\ (C)\]
</blockquote>

<blockquote>
\[P\ (D_2 \cap C_2) = P\ (D_2 \mid C_2) \times P\ (C_2)\]
</blockquote>

<blockquote>
\[P\ (D_2 \cap C_3) = P\ (D_2 \mid C_3) \times P\ (C_3)\]
</blockquote>

<p>For the first expression, we know that \(P\ (D_2 \mid C)\) is \(1\over2\) because if we pick the first door and correctly guess that it has the car behind it, Monty may open either the second or third door because they will both have goats. We also know that \(P\ (C)\) is \(1\over3\) as it is one of our priors, therefore we are left with a final value of \(1\over6\)</p>

<p>Taking a look at the second expression, we can deduce the value of \(P\ (D_2 \mid C_2)\) by thinking about the situation: what is the chance Monty will open the second door if the car is behind the second door? 0, as Monty will never reveal the door with the car behind it. Therefore the value for the second expression is left at 0.</p>

<p>Looking at the third and last expression, we can deduce the value of \(P\ (D_2 \mid C_3)\) will be 1 because if the car is behind the third door, and Monty must not reveal the car, and we’ve picked the first door, Monty has no choice but to open the second door to reveal a goat. This is multiplied by \(1\over3\) which is the initial probability of the car being behind the third door. This leaves us with a final value of \(1\over3\).</p>

<p>Now, adding all these values togehter, we find that:</p>

<blockquote>
\[P (D_2) = {1\over2}\]
</blockquote>

<p>We now have all the values we need, and can substitute everything into the formula:</p>

<blockquote>
\[P\ (C \mid D_2) = \\{\\{1\over2} \times {1\over3}\over{1\over2}} = {1\over3}\]
</blockquote>

<blockquote>
\[P\ (\overline{C} \mid D_2) = 1 - {1\over3} = {2\over3}\]
</blockquote>

<blockquote>
\[\therefore\ \ P\ (\overline{C} \mid D_2)\ \ &gt;\ \ P\ (C \mid D_2)\]
</blockquote>

<p>Seeing as this is the case, according to probability theory, switching doors is the best strategy.</p>

<h2 id="naive-monte-carlo-approach">Naive Monte Carlo Approach</h2>

<p>Monte Carlo <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">methods</a> are a very large class of algorithms designed to deduce probability by relying on repeatedly random sampling and drawing a numerical result. This approach can be applied to our problem, where we run the Monte Carlo problem scenario numerous times, and always stick to one of the two strategies and then we can compare the number of wins to the losses.</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// language: javascript</span>

<span class="kd">function</span> <span class="nx">getRandomInt</span><span class="p">(</span><span class="nx">max</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="nb">Math</span><span class="p">.</span><span class="nx">floor</span><span class="p">(</span><span class="nb">Math</span><span class="p">.</span><span class="nx">random</span><span class="p">()</span> <span class="o">*</span> <span class="nb">Math</span><span class="p">.</span><span class="nx">floor</span><span class="p">(</span><span class="nx">max</span><span class="p">));</span>
<span class="p">}</span>

<span class="kd">const</span> <span class="nx">doors</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">];</span>

<span class="c1">// keep track of how many times each strategy wins</span>
<span class="kd">let</span> <span class="nx">switchWins</span><span class="p">,</span> <span class="nx">keepWins</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

<span class="c1">// run the scenario 1000 times, and always switch doors </span>
<span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// getRandomInt(3) will return 0, 1 or 2</span>
    <span class="kd">const</span> <span class="nx">car</span> <span class="o">=</span> <span class="nx">doors</span><span class="p">[</span><span class="nx">getRandomInt</span><span class="p">(</span><span class="mi">3</span><span class="p">)];</span>
    <span class="kd">const</span> <span class="nx">ourChoice</span> <span class="o">=</span> <span class="nx">doors</span><span class="p">[</span><span class="nx">getRandomInt</span><span class="p">(</span><span class="mi">3</span><span class="p">)];</span>
    <span class="kd">const</span> <span class="nx">montyChoice</span> <span class="o">=</span> <span class="nx">doors</span><span class="p">[</span><span class="nx">getRandomInt</span><span class="p">(</span><span class="mi">3</span><span class="p">)];</span>
    <span class="k">do</span> <span class="p">{</span>
        <span class="nx">switchWins</span> <span class="o">++</span><span class="p">;</span> 
        <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">TEest</span><span class="dl">"</span><span class="p">)</span>
    <span class="p">}</span> <span class="k">while</span> <span class="p">(</span><span class="nx">switchWins</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">)</span>
<span class="p">}</span>





<span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">getRandomInt</span><span class="p">(</span><span class="mi">3</span><span class="p">));</span>
<span class="c1">// expected output: 0, 1 or 2</span>

<span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">getRandomInt</span><span class="p">(</span><span class="mi">1</span><span class="p">));</span>
<span class="c1">// expected output: 0</span>

<span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nb">Math</span><span class="p">.</span><span class="nx">random</span><span class="p">());</span>
<span class="c1">// expected output: a number between 0 and 1</span>

</code></pre></div></div>

<hr />
<hr />
<hr />

<h1 id="testing-blocks">Testing blocks</h1>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// bernoulli(0.6) // same as flip(0.6)</span>
<span class="nx">viz</span><span class="p">(</span><span class="nx">Bernoulli</span><span class="p">(</span> <span class="p">{</span> <span class="na">p</span><span class="p">:</span> <span class="mf">0.6</span> <span class="p">}</span> <span class="p">)</span> <span class="p">)</span>
</code></pre></div></div>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// language: javascript</span>
<span class="kd">const</span> <span class="nx">helloWorld</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">Helo wrld</span><span class="dl">"</span>
<span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">helloWorld</span><span class="p">);</span>
</code></pre></div></div>
<p><strong>Math?</strong>
\(P(B \mid A) := \frac{P(B \cap A)}{P(A)}\)
\(x = {-b \pm \sqrt{b^2-4ac} \over 2a}\)</p>

<h1 id="old-stuff">Old stuff</h1>
<p>[Note: This course is still being developed. Any feedback would be greatly appreciated and can be sent to <code class="language-plaintext highlighter-rouge">tessler@mit.edu</code>]</p>

<p>Learning statistics is like learning pottery. With pottery, you can learn how to make different shapes (e.g. a bowl, a vase, a spoon) without understanding general principles. The other way is to learn the basic strokes of forming pottery (e.g. how to mold a curved surface, a flat surface, long pointy things). In this course, we are going to learn the basic strokes of statistics, and compose those strokes to make shapes you’ve seen before (e.g. a t-test), some shapes you’ve probably never seen before, and develop ideas how you would make new shapes if you needed to. We won’t learn <em>what tests apply to what data types</em> but instead foster the ability to reason through data analysis. We will do this through the lens of Bayesian statistics, though the basic ideas will aid your understanding of classical (frequentist) statistics as well.</p>

<h2 id="chapters">Chapters</h2>

<ol>
  <li>
    <p><strong><a class="chapter-link" href="/bdappl/chapters/01-intro.html">Why analyze data</a></strong><br />
     <em>Course overview</em></p>
  </li>
  <li>
    <p><strong><a class="chapter-link" href="/bdappl/chapters/02-introPPL.html">Probabilistic programming</a></strong><br />
     <em>A brief introduction.</em></p>
  </li>
  <li>
    <p><strong><a class="chapter-link" href="/bdappl/chapters/03-simpleModels.html">Learning about a hypothesis</a></strong><br />
     <em>Models formalize hypotheses</em></p>
  </li>
  <li>
    <p><strong><a class="chapter-link" href="/bdappl/chapters/04-hypothesisTesting.html">Comparing hypotheses</a></strong><br />
     <em>Hypothesis testing is model comparison</em></p>
  </li>
  <li>
    <p><strong><a class="chapter-link" href="/bdappl/chapters/05-patterns.html">Causal models</a></strong><br />
     <em>Reasoning with structured knowledge</em></p>
  </li>
  <li>
    <p><strong><a class="chapter-link" href="/bdappl/chapters/08-bda-bcm.html">Analyzing Bayesian cognitive models</a></strong><br />
     <em>The fully Bayesian treatment</em></p>
  </li>
</ol>

<h2 id="appendix">Appendix</h2>

<ol>
  <li>
    <p><strong><a class="chapter-link" href="/bdappl/chapters/app-01-priors.html">Coming up with priors</a></strong><br />
     <em>Systematically interrogating one’s knowledge</em></p>
  </li>
  <li>
    <p><strong><a class="chapter-link" href="/bdappl/chapters/app-02-inference.html">Bayesian inference in a probabilistic program</a></strong><br />
     <em>Understanding observe, condition, and factor via rejection sampling</em></p>
  </li>
</ol>

<h2 id="citation">Citation</h2>

<p>M. H. Tessler (in prep). <em>Bayesian data analysis: An introduction using probabilistic programs</em>. Retrieved <span class="date"></span> from https://mhtess.github.io/bdappl/</p>

<h2 id="useful-resources">Useful resources</h2>

<h4 id="webppl-support-and-packages">WebPPL support and packages</h4>

<ul>
  <li><a href="http://webppl.org">webppl.org</a>: An online editor for WebPPL</li>
  <li><a href="http://webppl.readthedocs.io/en/master/">WebPPL documentation</a></li>
  <li><a href="https://groups.google.com/forum/?utm_medium=email&amp;utm_source=footer#!forum/webppl-dev">WebPPL dev Google Group</a>: Public forum for discussing issues with WebPPL</li>
  <li><a href="http://probmods.github.io/webppl-viz/">WebPPL-viz</a>: A summary of the vizualization options in WebPPL</li>
  <li><a href="https://github.com/mhtess/rwebppl">RWebPPL</a>: If you would rather use WebPPL within R</li>
  <li>WebPPL <a href="http://webppl.readthedocs.io/en/dev/packages.html">packages</a> (e.g. csv, json, fs).</li>
  <li><a href="https://github.com/mhtess/webppl-bda">A WebPPL package with useful BDA helper functions</a></li>
</ul>

<h4 id="basic-webppl-tutorials">Basic WebPPL tutorials</h4>

<ul>
  <li><a href="http://dippl.org/chapters/02-webppl.html">WebPPL intro from DIPPL</a>.</li>
  <li><a href="http://agentmodels.org/chapters/2-webppl.html">WebPPL intro from AgentModels</a>.</li>
</ul>

<h4 id="bayesian-data-analysis-using-webppl">Bayesian Data Analysis (using WebPPL)</h4>

<ul>
  <li><a href="http://www.problang.org/chapters/app-01-probability.html">Probabilities and Bayes Rule in WebPPL</a> by Michael Franke</li>
  <li><a href="http://michael-franke.github.io/statistics,/modeling/2017/07/07/BF_computation.html">Comparing methods for computing Bayes Factors</a> by Michael Franke</li>
  <li><a href="http://www.problang.org/chapters/app-04-BDA.html">BDA of Bayesian language models</a></li>
  <li><a href="http://web.stanford.edu/class/psych201s/">Old BDA course syllabus</a> by MH Tessler</li>
</ul>

<h4 id="other-webppl-applications">Other WebPPL applications</h4>

<ul>
  <li><a href="http://probmods.org/">Probabilistic Models of Cognition</a>: An introduction to computational cognitive science and the probabilistic programming language WebPPL</li>
  <li><a href="http://problang.org">Probabilistic Language Understanding</a>: An introduction to probabilistic models of language (in particular, the Rational Speech Act theory)</li>
  <li><a href="http://agentmodels.org">Modeling Agents with Probabilistic Programs</a>: An introduction to formal models of rational agents using WebPPL</li>
  <li><a href="http://forestdb.org">Forest</a>: A Repository for probabilistic models</li>
</ul>

<h3 id="great-textbooks-on-bayesian-data-analysis">Great textbooks on Bayesian Data Analysis</h3>

<ul>
  <li><a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis</a> (Kruschke)</li>
  <li><a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian Data Analysis</a> (Gelman)</li>
  <li><a href="https://bayesmodels.com">Bayesian Cognitive Modeling</a> (Lee &amp; Wagenmakers)</li>
</ul>

:ET